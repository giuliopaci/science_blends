Task: Distributed Computing
Description: Debian Science Distributed Computing packages
 This metapackage will install Debian Science packages useful for
 various types of distributed computing, such as grid-, cloud-, cluster-
 and parallel-computing.


Depends: ipython
Why: Provides ipcluster/ipcontroller/ipengine for Python-based distributed
     computing

Depends: torque-common, torque-server

Depends: nordugrid-arc-nox

Depends: gridengine-client, gridengine-exec, gridengine-master, gridengine-qmon

Depends: globus-core

Depends: openmpi-bin, mpich2

Depends: openmpipython, mpich2python, python-mpi

Suggests: hpcc

 ; Added by blends-inject 0.0.7. [Please note here if modified manually]
Suggests: condor
Homepage: http://www.cs.wisc.edu/condor
Language: C++, Perl
WNPP: 233482
Responsible: NeuroDebian Team <team@neuro.debian.net>
License: Apache-2.0
Pkg-URL: http://neuro.debian.net/pkgs/condor.html
Pkg-Description: workload management system
 Like other full-featured batch systems, Condor provides a job queueing
 mechanism, scheduling policy, priority scheme, resource monitoring, and
 resource management. Users submit their serial or parallel jobs to Condor,
 Condor places them into a queue. It chooses when and where to run the jobs
 based upon a policy, carefully monitors their progress, and ultimately
 informs the user upon completion.
 .
 Unlike more traditional batch queueing system, Condor can also effectively
 harness wasted CPU power from otherwise idle desktop workstations. Condor
 does not require a shared file system across machines - if no shared file
 system is available, Condor can transfer the job's data files on behalf of
 the user.
Published-Authors: Michael Litzkow, Miron Livny, and Matt Mutka
Published-In: Proceedings of the 8th International Conference of Distributed Computing Systems, pp. 104-111
Published-Title: Condor - A Hunter of Idle Workstations
Published-Year: 1988
Registration: http://www.cs.wisc.edu/condor/downloads-v2/

Suggests: coop-computing-tools
Published-Authors: Douglas Thain, Christopher Moretti, and Jeffrey Hemmes
Published-DOI: 10.1007/s10723-008-9100-5
Published-In: Journal of Grid Computing, 7, 51-72
Published-Title: Chirp: A Practical Global Filesystem for Cluster and Grid Computing
Published-Year: 2009

 ; Added by blends-inject 0.0.7. [now official package]
Suggests: python-mpi4py

 ; Added by blends-inject 0.0.7. [Please note here if modified manually]
Depends: dmtcp
Published-Authors: Jason Ansel, Kapil Arya, and Gene Cooperman
Published-In: 23rd IEEE International Parallel and Distributed Processing Symposium (IPDPS'09).
Published-Title: DMTCP: Transparent Checkpointing for Cluster Computations and the Desktop
Published-Year: 2009

 ; Added by blends-inject 0.0.7. [Please note here if modified manually]
Suggests: psom
Homepage: http://code.google.com/p/psom/
Language: Matlab/Octave
Responsible: NeuroDebian Team <team@neuro.debian.net>
License: MIT/Expat
Pkg-Description: pipeline system for Octave and Matlab
 PSOM is a lightweight library to manage complex multi-stage data processing. A
 pipeline is a collection of jobs, i.e. Matlab or Octave code with a well
 identified set of options that are using files for inputs and outputs. To
 use PSOM, the only requirement is to generate a description of a pipeline in
 the form of a simple Matlab/Octave structure. PSOM then automatically offers
 the following services:
 .
  * Run jobs in parallel using multiple CPUs or within a distributed computing
    environment.
  * Generate log files and keep track of the pipeline execution. These logs are
    detailed enough to fully reproduce the analysis.
  * Handle job failures: successful completion of jobs is checked and failed
    jobs can be restarted.
  * Handle updates of the pipeline: change options or add jobs and let PSOM
    figure out what to reprocess.
